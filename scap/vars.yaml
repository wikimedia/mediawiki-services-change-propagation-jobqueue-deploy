# log-related variables
log_name: cpjobqueue
log_file: /tmp/cpjq.log
rsyslog_port: 10514
# metrics
metrics_name: cpjobqueue
metrics_host: localhost
metrics_port: 8252
# service
name: cpjobqueue
port: 7200
proxy:
site: datacenter1
broker_list: localhost:9092
jobrunner_uri: http://localhost/rpc/RunSingleJob.php
videoscaler_uri: http://localhost/rpc/RunSingleJob.php
redis_path: /var/run/redis.sock
redis_pass:
env: production
kafka_max_bytes: 4194304
kafka_compression_codec: snappy
# The default concurrency is used whenever no specific settings are set for a job.
concurrency: 10
# All the jobs listed below get their own rule, which transfers to
# their own processing unit - each type of job listed explicitly is processed
# by a separate worker in change-prop.
high_traffic_jobs_config:
  ThumbnailRender:
    concurrency: 20
  categoryMembershipChange:
    concurrency: 200
  # CNDPurge is quite low-volume, but it uses delayed execution,
  # so avoid putting it together with other low-volume jobs so that it doesn't
  # block execution for others.
  cdnPurge:
    concurrency: 5
  ORESFetchScoreJob:
    concurrency: 20
  # RecordLinks is normally low-volume, but could have big spikes
  # when maintenance scripts are run. Elevated concurrency
  RecordLintJob:
    concurrency: 50
    consumer_batch_size: 10
    php7: true
  wikibase-addUsagesForPage:
    concurrency: 30
  constraintsRunCheck:
    concurrency: 30
  # For cirrus search jobs the retries are built into the job itself,
  # so disable the retries by change-prop. We need special rules for cirrus
  # jobs because they need special configuration.
  cirrusSearchCheckerJob:
    disable_delayed_execution: true #T198462
    retry_limit: 0
  cirrusSearchDeleteArchive:
    retry_limit: 0
    concurrency: 5
  cirrusSearchDeletePages:
    retry_limit: 0
    concurrency: 5
  cirrusSearchElasticaWrite:
    reenqueue_delay: 3600
    retry_limit: 0
  cirrusSearchIncomingLinkCount:
    retry_limit: 0
    concurrency: 15
  cirrusSearchLinksUpdate:
    retry_limit: 0
    concurrency: 100
  cirrusSearchLinksUpdatePrioritized:
    retry_limit: 0
    concurrency: 150
  cirrusSearchOtherIndex:
    retry_limit: 0
    concurrency: 5
# Videoscaler jobs point to a different LVS, so they need special treatment
# as well - thus special rules.
videoscaler_jobs_config:
  webVideoTranscode:
    timeout: 86400000
    concurrency: 50
  webVideoTranscodePrioritized:
    concurrency: 30
    timeout: 86400000
# Some jobs require partitioning according to MariaDB shards.
partitioned_jobs_config:
  refreshLinks:
    # This is the concurrency for the partitioner
    # itself, it's does not actually touch Mediawiki, only re-enqueues the
    # jobs according to proper partitions
    partitioner_concurrency: 200
    # This is the concurrency of the individual partitions, so overall concurrency
    # is 8 * 20 = 160
    partition_concurrency: 20
  htmlCacheUpdate:
    partitioner_concurrency: 50
    # This is the concurrency of the individual partitions, so overall concurrency
    # is 8 * 4 = 32
    # The load of htmlCacheUpdate is uneven across partitions, so we are using a bit
    # higher overall concurrency then needed.
    partition_concurrency: 4
    php7: true
# All the jobs not explicitly specified in the config are combined into the
# `low_traffic_jobs` rule, so they share a worker. The low_traffic_concurrency
# is shared between all the jobs other then the exceptions listed above.
#
# Most of the topics are empty most of the time, so a lot of slots are just waiting
# for the `consume` method to timeout and do nothing.
# So a significantly higher concurrency is needed to account for that.
low_traffic_concurrency: 50
# The list of jobs for which we enable PHP7. This config is temporary since we will
# eventually switch all the jobs to using PHP7. For all the jobs that use their own
# special configs this list is not needed as the PHP7 cookie can be specified directly
# in the job definition.
low_traffic_php7_enabled:
  - updateBetaFeaturesUserCounts


